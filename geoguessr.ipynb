{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the [YouTube video](https://www.youtube.com/watch?v=mM_dC1HVAQ4) first for more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import math\n",
    "import urllib.request\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the data\n",
    "\n",
    "### Set the boundaries\n",
    "\n",
    "Since we are just collecting data for the USA, we want to set the latitude and longitude boundaries to be restricted to the USA. These values have been multiplied by 10,000,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = 247433195\n",
    "lat_max = 493457868\n",
    "lon_min = -1247844079\n",
    "lon_max = -669513812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street view API parameters\n",
    "\n",
    "This project uses the [Google Street View API](https://developers.google.com/maps/documentation/streetview/overview) to collect street view images. The parameters are set according to [this doc](https://developers.google.com/maps/documentation/streetview/request-streetview). Note that you will need to obtain your own API key by following [this guide](https://developers.google.com/maps/documentation/streetview/cloud-setup).\n",
    "\n",
    "**Scraping data using the Google Street View API is against Google's terms of service. Use at your own risk. Google may be able to tell that you are scraping data and give your account a warning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '&key=YOUR-API-KEY'\n",
    "size = '&size=640x640'\n",
    "radius = '&radius=1000'\n",
    "source = '&source=outdoor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the images\n",
    "\n",
    "The following code will download 1000 streetview images from random points in within the USA. As it collects the images it will also record the image name, latitude, and longitude to a CSV file, which will be needed later. It first calls the [Street View Metadata API](https://developers.google.com/maps/documentation/streetview/metadata) to ensure that the image is valid. If the image is valid, then it will call the actual Street View API and save the image to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICTURES_TO_COLLECT = 1000\n",
    "IMAGE_DIRECTORY = 'images/USA/'\n",
    "ANNOTATION_CSV = 'annot.csv'\n",
    "\n",
    "with open(ANNOTATION_CSV, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    while i < PICTURES_TO_COLLECT:\n",
    "        lat = random.randrange(lat_min, lat_max) / 10000000\n",
    "        lng = random.randrange(lng_min, lng_max) / 10000000\n",
    "\n",
    "        location = '&location=' + str(lat) + ',' + str(lng)\n",
    "\n",
    "        parameters = size + location + radius + source + key\n",
    "        metadata_url = 'https://maps.googleapis.com/maps/api/streetview/metadata?' + parameters\n",
    "\n",
    "        response = urllib.request.urlopen(metadata_url, timeout=30)\n",
    "        data = response.read()\n",
    "        encoding = response.info().get_content_charset('utf-8')\n",
    "        metadata = json.loads(data.decode(encoding))\n",
    "\n",
    "        if metadata['status'] == 'OK':\n",
    "            streetview_url = 'https://maps.googleapis.com/maps/api/streetview?' + parameters\n",
    "            name = 'USA_' + str(i) + '.jpg'\n",
    "            urllib.request.urlretrieve(streetview_url, IMAGE_DIRECTORY + name)\n",
    "            writer.writerow([name, str(metadata['location']['lat']), str(metadata['location']['lng'])])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define boxes\n",
    "\n",
    "The USA will be divided into multiple boxes which will be used to guess where a given streetview is located. The bounding box which was used to collect the images does not perfectly match the USA. Because of this, we define the boxes which are within the bounding box, but not in the USA. We will exclude images that were collected from these boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = 24.7433195\n",
    "lat_max = 49.3457868\n",
    "lon_min = -124.7844079\n",
    "lon_max = -66.9513812\n",
    "\n",
    "# Divide the country into 50 total boxes. 10 boxes wide and 5 boxes tall.\n",
    "x_boxes = 10\n",
    "y_boxes = 5\n",
    "\n",
    "# These boxes are outside of the USA\n",
    "outside = [[0,0], [1,0], [2,0], [3,0], [5,0], [6,0], [8,0], [9,0],\n",
    "           [0,1], [8,1], [9,1], [9,2], [7,4], [8,4]]\n",
    "\n",
    "box_width = (lon_max - lon_min) / x_boxes\n",
    "box_height = (lat_max - lat_min) / y_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load annotations\n",
    "\n",
    "Using the CSV containing the annotations for the images, the annotations are loaded into memory as long as the image is within the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_names = os.listdir(IMAGE_DIRECTORY)\n",
    "all_ims = []\n",
    "with open(ANNOTATION_CSV, newline='') as datafile:\n",
    "    reader = csv.reader(datafile, delimiter=',')\n",
    "    for row in reader:\n",
    "        if row[0] in im_names:\n",
    "            lat = float(row[1])\n",
    "            lon = float(row[2])\n",
    "            row_n = math.floor((lat-lat_min) / box_height)\n",
    "            col_n = math.floor((lon-lon_min) / box_width)\n",
    "            if row_n >= y_boxes or col_n >= x_boxes:\n",
    "                continue\n",
    "            if [col_n, row_n] in outside:\n",
    "                continue\n",
    "            all_ims.append([row[0], float(row[1]), float(row[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ML models\n",
    "\n",
    "### Pretrained model\n",
    "\n",
    "This project uses feature extraction and transfer learning. View [this tutorial](https://developers.google.com/machine-learning/practica/image-classification) for a hands on example of how convolutional neural networks work, and how we can use feature extraction. The pretrained model we will be using for feature extraction is [MobileNetV2](https://keras.io/api/applications/mobilenet/#mobilenetv2-function). The input to this model will be streetview image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 224\n",
    "input_height = 224\n",
    "pre_trained_model = keras.applications.MobileNetV2(\n",
    "    input_shape=(input_width, input_height, 3), \n",
    "    include_top=False,\n",
    "    weights='imagenet', \n",
    "    pooling='avg')\n",
    "\n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier\n",
    "\n",
    "We will define a simple classifier model which takes the output features of the pretrained model as inputs. This model will output a final guess for the location of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(50, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess images\n",
    "\n",
    "### Load images\n",
    "\n",
    "The following code loads all of the images into a numpy array and labels all of the images with the corresponding box they belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch = []\n",
    "labels = []\n",
    "\n",
    "random.shuffle(all_ims)\n",
    "\n",
    "for im_info in all_ims:\n",
    "    im = Image.open(IMAGE_DIRECTORY + im_info[0]).resize((input_width, input_height))\n",
    "    im_batch.append(np.array(im))\n",
    "    lat = im_info[1]\n",
    "    lon = im_info[2]\n",
    "    row_n = math.floor((lat-lat_min) / box_height)\n",
    "    col_n = math.floor((lon-lon_min) / box_width)\n",
    "    label = [0 for i in range(50)]\n",
    "    label[row_n * x_boxes + col_n] = 1\n",
    "    labels.append(label)\n",
    "            \n",
    "labels = np.array(labels)\n",
    "im_batch = np.array(im_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features\n",
    "\n",
    "The images are preprocessed for the MobileNetV2 model and are then inputed into the model. The output of the model is the extracted features for all of the images. These features will be used as input to the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_batch = keras.applications.mobilenet_v2.preprocess_input(im_batch)\n",
    "data = pre_trained_model.predict(im_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "The classifier model is trained on the output of the pretrained model. The model does not need to train for many epochs before the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 20\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='acc')\n",
    "\n",
    "history = model.fit(\n",
    "    data,\n",
    "    labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "\n",
    "Evaluate the loss and accuracy of the model after it finishes training, and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve a list of loss results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Get range of epochs\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs_range, acc, label='Training')\n",
    "plt.plot(epochs_range, val_acc, label='Validation')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs_range, loss, label='Training')\n",
    "plt.plot(epochs_range, val_loss, label='Validation')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "This command saves the model on the disk and can be used again in other programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('geoguessr_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model\n",
    "\n",
    "### Load image\n",
    "\n",
    "Load a streetview image to test with the model. Run the image through the pretrained model and then send the features through the newly trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_im = Image.open('images/test_image.jpg').resize((input_width, input_height))\n",
    "im_p = np.array([np.array(base_im)])\n",
    "im_p = keras.applications.mobilenet_v2.preprocess_input(im_p)\n",
    "features_p = pre_trained_model.predict(im_p)\n",
    "prediction = model.predict(features_p)[0]\n",
    "\n",
    "plt.imshow(base_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make guess\n",
    "\n",
    "The following code will plot a map of the USA and place the guess as a pink dot on the map. It shades each box on the map based on the confidence of the AI that the image belongs to that box. The darker the box, the more confident the AI is that the image belongs to that box. The final guess is made by taking a weighted average of each box. The more confident the AI is that the image belongs to a box, the closer the final guess will be to that box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('geoguessr_model.h5')\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "map = Basemap(projection='mill', llcrnrlon=lon_min, llcrnrlat=lat_min, urcrnrlon=lon_max, urcrnrlat=lat_max)\n",
    "map.drawmapboundary(fill_color='aqua')\n",
    "map.drawcountries()\n",
    "map.fillcontinents(color='coral',lake_color='aqua')\n",
    "map.drawcoastlines()\n",
    "\n",
    "centers = [0 for _ in range(x_boxes*y_boxes)]\n",
    "for i in range(x_boxes):\n",
    "    for j in range(y_boxes):\n",
    "        confidence = prediction[j*x_boxes+i]\n",
    "        \n",
    "        x_orig = box_width * i\n",
    "        y_orig = box_height * j\n",
    "        x_offset = box_width * (i+1)\n",
    "        y_offset = box_height * (j+1)\n",
    "        lons = [lon_min+x_orig, lon_min+x_offset, lon_min+x_offset, lon_min+x_orig]\n",
    "        lats = [lat_min+y_orig, lat_min+y_orig, lat_min+y_offset, lat_min+y_offset]\n",
    "        centers[j*x_boxes+i] = [sum(lats)/4, sum(lons)/4]\n",
    "\n",
    "        x, y = map(lons, lats)\n",
    "        xy = zip(x,y)\n",
    "        poly = Polygon( list(xy), fill=True, linewidth=2, facecolor='black', alpha=confidence, edgecolor='black')\n",
    "        plt.gca().add_patch(poly)\n",
    "        \n",
    "lat_p = 0\n",
    "lon_p = 0\n",
    "for i in range(x_boxes*y_boxes):\n",
    "    lat_p += prediction[i] * centers[i][0]\n",
    "    lon_p += prediction[i] * centers[i][1]\n",
    "x, y = map(lon_p, lat_p)\n",
    "map.plot(x, y, marker='o',color='m', zorder=10, markersize=10)\n",
    "    \n",
    "print(str(lat_p) + ', ' + str(lon_p))\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
